{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify dog-breed using Transfer Learning (TensorFlow for Poets Library)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link for dataset containing pictures of 120 different breeds of dogs  : http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I start with Transfer Learning since only 20,580 images distributed across 120 classes is not large enough to train an image classification model from scratch. \n",
    "\n",
    "To implement this solution I will use TensorFlow For Poets library, which uses a model trained on the ImageNet Large Visual Recognition Challenge dataset. These models can differentiate between 1,000 different classes, like Dalmatian or dishwasher. It provides a wide ranges of choices for model architecture which can be used in future for improvements. \n",
    "\n",
    "The following commands are **Linux** commands to be run in a terminal. \n",
    "\n",
    "To begin with we first declare the IMAGE_SIZE and ARCHITECTURE as linux variables. Having a smaller image size is helpful in making the model train faster. We can change this parameter to larger values in future if we are not satisfied with the results. We have currently chosen the mobilenet architecture. MobileNet is a a small efficient convolutional neural network. The \"0.5\" represents the relative size of the model as a fraction of the largest MobileNet."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "IMAGE_SIZE=224\n",
    "ARCHITECTURE=\"mobilenet_0.50_${IMAGE_SIZE}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top layer receives as input a 1001-dimensional vector for each image. We train a softmax layer on top of this representation. Assuming the softmax layer contains N labels, this corresponds to learning N + 1001*N  model parameters corresponding to the learned biases and weights."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "python -m scripts.retrain \\\n",
    "  --bottleneck_dir=tf_files/bottlenecks \\\n",
    "  --how_many_training_steps=500 \\\n",
    "  --model_dir=tf_files/models/ \\\n",
    "  --summaries_dir=tf_files/training_summaries/\"${ARCHITECTURE}\" \\\n",
    "  --output_graph=tf_files/retrained_graph.pb \\\n",
    "  --output_labels=tf_files/retrained_labels.txt \\\n",
    "  --architecture=\"${ARCHITECTURE}\" \\\n",
    "  --image_dir=/home/gvlab/Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above command:\n",
    "* bottleneck_dir: Folder string holding cached files of bottleneck values.\n",
    "* model_dir: Folder where the models are stored\n",
    "* summaries_dir: Folder to write summaries for TensorBoard\n",
    "* output_graph, output_labels: the trained graph and labels with the weights stored as constants\n",
    "\n",
    "The default % of the images for each class as test set is already 10 %, so that was left unchanged. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/question2Image1New.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above image is a screenshot of the training results of our model. As we can see, we have a final accuracy of 67.9%. We will further change some parameters to see if we can improve on that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below graph the orange line shows the accuracy of the model on the training data. While the blue line shows the accuracy on the test set (which was not used for training)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/question2Image1Accuracy.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tested our model on the following two images, using the linux commands again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/question2Test1Image.jpg\">"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "python -m scripts.label_image \\\n",
    "    --graph=tf_files/retrained_graph.pb  \\\n",
    "    --image=/home/gvlab/Images/n02085782-Japanese_spaniel/n02085782_1964.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/question2Image1Test1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/question2Test2Image.jpg\">"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "python -m scripts.label_image \\\n",
    "    --graph=tf_files/retrained_graph.pb  \\\n",
    "    --image=/home/gvlab/Images/n02097209-standard_schnauzer/n02097209_2194.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/question2Image1Test2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, the model has correctly classified the images although we have confidence scores of only 57% and 43% respectively for the above two images.\n",
    "\n",
    "In the following steps we will change the training rate and the number of training steps to see if it improves our model. \n",
    "With a lower training rate, the training will take longer, but the overall precision might increase. Again, with increasing the number of training steps we can likely get improved results (i.e. higher accuracy) by training for longer. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "python -m scripts.retrain \\\n",
    "  --bottleneck_dir=tf_files/bottlenecks \\\n",
    "  --training_rate=0.001 \\\n",
    "  --how_many_training_steps=4000 \\\n",
    "  --model_dir=tf_files/models/ \\\n",
    "  --summaries_dir=tf_files/training_summaries/\"${ARCHITECTURE}\" \\\n",
    "  --output_graph=tf_files/retrained_graph.pb \\\n",
    "  --output_labels=tf_files/retrained_labels.txt \\\n",
    "  --architecture=\"${ARCHITECTURE}\" \\\n",
    "  --image_dir=/home/gvlab/Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/question2Image2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the above screenshot we were able to slightly increase the test accuracy of our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below graph the orange line shows the accuracy of the model on the training data. While the blue line shows the accuracy on the test set (which was not used for training). \n",
    "\n",
    "We can notice that while the accuracy of the model on training data keeps on increasing, the accuracy on the test data remains the same. This shows that the model is overfitting. To solve this problem we can try to get more training examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/question2Image1Accuracy2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tested our new model on the same two images as the first model, and we find that the confidence score are much better, with 77% and 94% respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/question2Test2Image2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/question2Image1Test12.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further improve on our results by tuning the hyperparameters such as training rate, using bigger image size, choosing a larger pre-trained model, etc.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myEnvPy3]",
   "language": "python",
   "name": "conda-env-myEnvPy3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
